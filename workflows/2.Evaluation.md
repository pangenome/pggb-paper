# Evaluation

Variables:

```shell
DIR_BASE=/lizardfs/guarracino/pggb-paper
DIR_GRAPHS=/lizardfs/guarracino/pggb-paper/graphs
DIR_GRAPHS_MC=/lizardfs/guarracino/pggb-paper/graphs_mc
DIR_EVALUATIONS=/lizardfs/guarracino/pggb-paper/evaluations
PATH_PANGENOMES_TSV=/lizardfs/guarracino/pggb-paper/data/pangenomes.tsv

ODGI=/home/guarracino/tools/odgi/bin/odgi-861b1c04f5622c5bb916a161c1abe812c213f1a5
RUN_GFA_2_EVALUATION=/lizardfs/guarracino/pggb-paper/scripts/gfa2evaluation.sh
RUN_GFA_2_EVALUATION_COPY_NUCMER=/lizardfs/guarracino/pggb-paper/scripts/gfa2evaluation.copy-nucmer.sh

# guix install python-scikit-learn python-seaborn
PANACUS=/home/guarracino/tools/panacus/target/release/panacus-bd492f54c05367d0fc5a2c3fb9bf23260ac8379e
PANACUS_VISUALIZE=/home/guarracino/tools/panacus/scripts/panacus-visualize.py

THREADS=48
```

SNVs evaluation with NUCMER:

```shell
mkdir -p $DIR_EVALUATIONS
cd $DIR_EVALUATIONS

#sed '1d' $PATH_PANGENOMES_TSV | sort -k 4n | grep athaliana | sed 's/47/23/g' | while read f p s n k G POA O REF; do
#sed '1d' $PATH_PANGENOMES_TSV | sort -k 4n | grep athaliana | sed 's/5000/10000/g' | while read f p s n k G POA O REF; do
#sed '1d' $PATH_PANGENOMES_TSV | sort -k 4n | grep athaliana | sed 's/5000/10000/g' | sed 's/47/23/g' | while read f p s n k G POA O REF; do
#sed '1d' $PATH_PANGENOMES_TSV | sort -k 4n | grep athaliana | sed 's/95/90/g' | while read f p s n k G POA O REF; do
sed '1d' $PATH_PANGENOMES_TSV | sort -k 4n | grep athaliana | sed 's/95/90/g' | sed 's/5000/10000/g' | while read f p s n k G POA O REF; do
  seq 1 1 | while read c; do
    echo $f $p $s $n $k $G $POA $O $REF $c;

    out=$(basename "$f" .fa.gz)_p$p.s$s.n$n.k$k.G$(echo $G | tr ',' '-').P$POA.O$(echo $O | sed 's/\.//g')_$c
    PATH_GFA=$DIR_GRAPHS/$out/*.final.gfa
    PATH_GFA=$(eval echo $PATH_GFA) # force '*' expansion
    sbatch -c $THREADS -p workers -J $(basename "$f" .fa.gz) --wrap "hostname; cd /scratch; /lizardfs/guarracino/pggb-paper/scripts/gfa2evaluation.parallel.sh $PATH_GFA $REF $DIR_EVALUATIONS/$out $THREADS;"
  done
done


#####################################################################################################
THREADS=48
PREFIX_REFERENCE=GCA_028009825.2
PREFIX=athaliana82.chr2.fa.gz.35d2267.e34d4cd.5244487.smooth.final
PREFIX=athaliana82.chr4.fa.gz.35d2267.e34d4cd.5244487.smooth.final
PATH_VCF="$PREFIX"."$PREFIX_REFERENCE".haplo.vcf
PATH_REF_SDF="$PREFIX"."$PREFIX_REFERENCE".sdf
zgrep '#CHROM' "$PATH_VCF".gz -m 1 | cut -f 10- | tr '\t' '\n' | while read HAPLO; do
  echo "$HAPLO"
  PATH_NUCMER_VCF=nucmer/"$HAPLO".vcf.gz
  PATH_PGGB_WAVED_VCF="$PREFIX"."$PREFIX_REFERENCE".haplo.waved.fixed."$HAPLO".max1.vcf.gz
  dist=1000
  rtg vcfeval \
      -t "$PATH_REF_SDF" \
      -b "$PATH_NUCMER_VCF" \
      -c "$PATH_PGGB_WAVED_VCF" \
      -T "$THREADS" \
      -e <(bedtools intersect -a <(bedtools merge -d $dist -i "$PATH_NUCMER_VCF") -b <(bedtools merge -d $dist -i "$PATH_PGGB_WAVED_VCF") | bedtools subtract -a stdin -b <(echo "GCA_028009825.2#1#CP116281.2\t0\t5314359\nGCA_028009825.2#1#CP116283.2\t0\t3829980")) \
      -o vcfeval_no-chr2-chr4-p-arm/haplo.waved/"$HAPLO"
done
zgrep '#CHROM' "$PATH_VCF".gz -m 1 | cut -f 10- | tr '\t' '\n' | while read HAPLO; do
  echo "$HAPLO"
  PATH_NUCMER_VCF=nucmer/"$HAPLO".vcf.gz
  PATH_PGGB_WAVED_VCF="$PREFIX"."$PREFIX_REFERENCE".haplo.waved.fixed."$HAPLO".max1.vcf.gz
  NUM_VARIANTS_NUCMER_TOTAL=$(zgrep '^#' -vc "$PATH_NUCMER_VCF")
  NUM_VARIANTS_PGGB_WAVED_TOTAL=$(zgrep '^#' -vc "$PATH_PGGB_WAVED_VCF")
  NUM_VARIANTS_NUCMER_TP=$(grep None vcfeval/haplo/"$HAPLO"/summary.txt | sed 's,/summary.txt:,,' | tr -s ' ' | cut -f 3 -d ' ')
  NUM_VARIANTS_PGGB_WAVED_TP=$(grep None vcfeval/haplo.waved/"$HAPLO"/summary.txt | sed 's,/summary.txt:,,' | tr -s ' ' | cut -f 4 -d ' ')
  FP_WAVED=$(grep None vcfeval/haplo.waved/"$HAPLO"/summary.txt | sed 's,/summary.txt:,,' | tr -s ' ' | cut -f 5 -d ' ')
  FN_WAVED=$(grep None vcfeval/haplo.waved/"$HAPLO"/summary.txt | sed 's,/summary.txt:,,' | tr -s ' ' | cut -f 6 -d ' ')
  NUM_VARIANTS_NUCMER_WAVED_EVALUATED=$(echo "$NUM_VARIANTS_NUCMER_TP + $FN_WAVED" | bc)
  NUM_VARIANTS_PGGB_WAVED_EVALUATED=$(echo "$NUM_VARIANTS_PGGB_WAVED_TP + $FP_WAVED" | bc)
  # xargs trims whitespaces
  grep None vcfeval/haplo.waved/"$HAPLO"/summary.txt |  tr -s ' ' | xargs | cut -f 2,3,4,5,6,7,8,9 -d ' ' | tr ' ' '\t' | \
      awk -v haplo=$HAPLO -v nucmer=$NUM_VARIANTS_NUCMER_TOTAL -v pggb=$NUM_VARIANTS_PGGB_WAVED_TOTAL -v nucmereval=$NUM_VARIANTS_NUCMER_WAVED_EVALUATED -v pggbeval=$NUM_VARIANTS_PGGB_WAVED_EVALUATED -v OFS='\t' '{print(haplo, $0, nucmer, pggb, nucmereval/nucmer, pggbeval/pggb)}' >> statistics.haplo.waved2.tsv
done
#####################################################################################################





cd $DIR_EVALUATIONS

for type in "" "waved."; do
  echo $type

  # All results
  ((echo -n replicate"\t"dataset"\t"; cat */statistics*.tsv | head -n 1 | tr -d '\n'; echo -e "\tpggb.evaluated"); ls */statistics.haplo.${type}tsv | while read f; do
    name=$(echo $f | cut -f 1 -d '/');
    sed '1d' $f | awk -v name="$name" -v OFS='\t' 'NF>=12 { print(name, $0) }' | awk -v OFS='\t' '{print(substr($1, length($1), 1),$0,$4+$5)}';
  done) | sort -k 1,1n -k 2,2 > nucmer-based_evaluation.${type}tsv

  # Average results
  # GCA_028009825.1 and GCA_028009825.2 are identical, so they create nan in the evaluation
  cat nucmer-based_evaluation.${type}tsv |
    awk '
    BEGIN { FS=OFS="\t" }
    NR>1 {
        count[($1 FS $2)]++
        for (i=4; i<=NF; i++) {  # Start from the 4th column
            sum[($1 FS $2 FS i)] += $i
        }
    }
    END {
        print "replicate", "dataset", "tp.baseline", "tp.call", "fp", "fn", "precision", "recall", "f1.score", "nucmer.tot", "pggb.tot", "nucmer.ratio", "pggb.ratio", "pggb.evaluated"
        for (key in count) {
            printf "%s", key
            for (i=4; i<=15; i++) {  # Adjust the indices here as well
                printf "%s%.6f", OFS, sum[key FS i] / count[key]
            }
            print ""
        }
    }' | sort -k 1,1n -k 2,2 > nucmer-based_evaluation.${type}mean.tsv
done

# Group chromosomes together
grep 'athaliana\|tomato\|soy' nucmer-based_evaluation.waved.mean.tsv | grep athaliana82 | grep p95.s10000.n82.k23.G700-900-1100.Pasm5.O0001 | awk '
    BEGIN { FS=OFS="\t" }
    {
        # Sum columns
        for (i = 3; i <= 6; i++) sum[i] += $i;
        for (i = 10; i <= 11; i++) sum[i] += $i;
        sum[14] += $14;

        # Average columns
        for (i = 7; i <= 9; i++) {
            avg[i] += $i;
            count[i]++;
        }
        for (i = 12; i <= 13; i++) {
            avg[i] += $i;
            count[i]++;
        }
    }
    END {
        # Print sums and averages in input column order
        for (i = 3; i <= 14; i++) {
            if (i >= 7 && i <= 9 || i >= 12 && i <= 13) {
                # Print average for these columns
                printf "%f%s", avg[i] / count[i], OFS;
            } else {
                # Print sum for these columns
                printf "%f%s", sum[i], OFS;
            }
        }
        print "";  # New line at the end of output
    }
'
```

SNVs and INDELs evaluation:

```shell
# Call variants
cd $DIR_GRAPHS

sed '1d' $PATH_PANGENOMES_TSV | sort -k 4n | grep 'hsapiens\|tomato\|athaliana' -v | while read f p s n k G POA O REF; do
  seq 1 1 | while read c; do
    if [[ $f == *"hsapiens"* ]]; then
      REF="grch38" # hsapiens variants are called w.r.t. grch38
    fi
    echo $f $p $s $n $k $G $POA $O $REF $c;

    out=$(basename "$f" .fa.gz)_p$p.s$s.n$n.k$k.G$(echo $G | tr ',' '-').P$POA.O$(echo $O | sed 's/\.//g')_$c
    PATH_GFA=$DIR_GRAPHS/$out/*.final.gfa
    PATH_GFA=$(eval echo $PATH_GFA) # force '*' expansion
    PREFIX=$(echo $PATH_GFA | sed 's/.gfa//g')

    sbatch -c $THREADS -p allnodes --job-name vg-$out --wrap "hostname; cd $DIR_GRAPHS/$out; vg deconstruct -P $REF -e -a -t $THREADS $PATH_GFA | bgzip -@ $THREADS -l 9 > $PREFIX.$REF.vcf.gz; vcfbub -l 0 -a 10000 --input $PREFIX.$REF.vcf.gz | vcfwave -I 1000 -t $THREADS > $PREFIX.$REF.decomposed.tmp.vcf; bcftools annotate -x INFO/TYPE $PREFIX.$REF.decomposed.tmp.vcf | awk '\$5 != \".\"' | bgzip -@ $THREADS -l 9 > $PREFIX.$REF.decomposed.vcf.gz; tabix $PREFIX.$REF.decomposed.vcf.gz; rm $PREFIX.$REF.decomposed.tmp.vcf; zcat $PREFIX.$REF.decomposed.vcf.gz | bcftools view -a -Ou | bcftools norm -m - --threads $THREADS -Ou | bcftools sort -m 40G -T /scratch/bcftools-sort.XXXXXX -Ou | bcftools norm -d exact -Ov --threads $THREADS | python3 /lizardfs/guarracino/rat_32samples/SV/fix_svtype_vcf.py | bgzip -@ $THREADS -l 9 > $PREFIX.$REF.decomposed.norm.vcf.gz; tabix $PREFIX.$REF.decomposed.norm.vcf.gz"
    # Fixed vcfwave
    #sbatch -c $THREADS -p headnode --job-name vg-$out --wrap "hostname; cd $DIR_GRAPHS/$out; vg deconstruct -P $REF -e -a -t $THREADS $PATH_GFA | bgzip -@ $THREADS -l 9 > $PREFIX.$REF.vcf.gz; vcfbub -l 0 -a 10000 --input $PREFIX.$REF.vcf.gz | /home/guarracino/tools/vcflib/build/vcfwave -I 1000 -t $THREADS > $PREFIX.$REF.decomposed2.tmp.vcf; bcftools annotate -x INFO/TYPE $PREFIX.$REF.decomposed2.tmp.vcf | awk '\$5 != \".\"' | bgzip -@ $THREADS -l 9 > $PREFIX.$REF.decomposed2.vcf.gz; tabix $PREFIX.$REF.decomposed2.vcf.gz; rm $PREFIX.$REF.decomposed2.tmp.vcf; zcat $PREFIX.$REF.decomposed2.vcf.gz | bcftools view -a -Ou | bcftools norm -m - --threads $THREADS -Ou | bcftools sort -m 40G -T /scratch/bcftools-sort.XXXXXX -Ou | bcftools norm -d exact -Ov --threads $THREADS | python3 /lizardfs/guarracino/rat_32samples/SV/fix_svtype_vcf.py | bgzip -@ $THREADS -l 9 > $PREFIX.$REF.decomposed2.norm.vcf.gz; tabix $PREFIX.$REF.decomposed2.norm.vcf.gz"
  done
done


# H. sapiens
cut -f 1 /lizardfs/erikg/HPRC/year1v2genbank/evaluation/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna -d ' ' | sed 's/>chr/>grch38#1#chr/g' > $DIR_BASE/vcfs/hsapiens/grch38.fa
samtools faidx $DIR_BASE/vcfs/hsapiens/grch38.fa
rtg format -o $DIR_BASE/vcfs/hsapiens/grch38.fa.sdf $DIR_BASE/vcfs/hsapiens/grch38.fa

# VCF files (from https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=submissions/B581EBA7-8BDE-4C7C-9DEA-78B99A051155--Yale_HPP_Year1_Variant_Calls/)
mkdir -p $DIR_BASE/vcfs/hsapiens
cd $DIR_BASE/vcfs/hsapiens
cut -f 2 $DIR_BASE/data/HPRC.deepvariant-vcf.urls.tsv | parallel -j 4 'wget -q {} && echo got {}'
ls $DIR_BASE/vcfs/hsapiens/*vcf.gz | while read VCF; do
  echo $VCF
  NAME=$(basename $VCF .vcf.gz)
  zcat $VCF | sed 's/chr/grch38#1#chr/g' | bgzip -@ 48 -l 9 > $NAME.pansn.vcf.gz
  rm $VCF
  tabix $NAME.pansn.vcf.gz
done

# Confident regions (from https://s3-us-west-2.amazonaws.com/human-pangenomics/index.html?prefix=working/HPRC/HG00438/assemblies/year1_freeze_assembly_v2/assembly_qc/dipcall_v0.2/)
cut -f 2 $DIR_BASE/data/HPRC.dipcall-confident-regions.urls.tsv | parallel -j 4 'wget -q {} && echo got {}'
ls $DIR_BASE/vcfs/hsapiens/*bed | while read BED; do
  echo $BED
  NAME=$(basename $BED .bed)
  cat $BED | sed 's/chr/grch38#1#chr/g' | sort -V | bgzip -@ 48 -l 9 > $NAME.confident-yes.pansn.bed.gz
  rm $BED
  tabix -p bed $NAME.confident-yes.pansn.bed.gz
done

# Stratification (from https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/genome-stratifications/v2.0/GRCh38/union/)
wget -c https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/genome-stratifications/v2.0/GRCh38/union/GRCh38_notinalldifficultregions.bed.gz # easy regions
wget -c https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/genome-stratifications/v2.0/GRCh38/union/GRCh38_alllowmapandsegdupregions.bed.gz # low map and SegDup
wget -c https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/genome-stratifications/v2.0/GRCh38/union/GRCh38_alldifficultregions.bed.gz # hard regions (low map and SegDup included)
for BED in GRCh38_notinalldifficultregions.bed.gz GRCh38_alllowmapandsegdupregions.bed.gz GRCh38_alldifficultregions.bed.gz; do
  zcat $BED | sed '1d' | sed 's/^chr/grch38#1#chr/g' | bgzip -@ 48 -l 9 > x
  mv x $BED
  tabix -p bed $BED
done

cd $DIR_BASE/evaluations_vcfeval
ls $DIR_GRAPHS/hsapiens*/*decomposed.vcf.gz | while read VCF; do
  NAME="$(dirname $VCF | rev | cut -f 1 -d '/' | rev)"
  echo $NAME

  sbatch -c 48 -p allnodes --job-name $NAME --wrap "hostname; bash $DIR_BASE/scripts/evaluation.speciesN.sh \
    $VCF \
    grch38#1#chr6 \
    $NAME \
    $DIR_BASE/evaluations_vcfeval \
    $DIR_BASE/vcfs/hsapiens/grch38.fa \
    $DIR_BASE/vcfs/hsapiens/grch38.fa.sdf \
    $DIR_BASE/vcfs/hsapiens \
    .GRCh38_no_alt.deepvariant.pansn.vcf.gz \
    ".all":"" \
    ".easy":$DIR_BASE/vcfs/hsapiens/GRCh38_notinalldifficultregions.bed.gz \
    ".hard":$DIR_BASE/vcfs/hsapiens/GRCh38_alldifficultregions.bed.gz" #\
    #".confident-yes":$DIR_BASE/vcfs/hsapiens/$SAMPLE.f1_assembly_v2.dip.confident-yes.pansn.bed.gz \
    #".lowmap-segdup":$DIR_BASE/vcfs/hsapiens/GRCh38_alllowmapandsegdupregions.bed.gz"
done

ls $DIR_GRAPHS/hsapiens*/*decomposed.vcf.gz | while read VCF; do
  NAME="$(dirname $VCF | rev | cut -f 1 -d '/' | rev)"
  echo $NAME

  grep None $DIR_BASE/evaluations_vcfeval/$NAME/vcfeval/*/summary.txt | grep easy -v | grep hard -v  | wc -l
  grep None hsapiens90.chr6.masked_p95.s10000.n90.k23.G700-900-1100.Pasm5.O0001_1/vcfeval/HG00438/summary.txt
done


# Tomato
mkdir -p $DIR_BASE/vcfs/tomato
cd $DIR_BASE/vcfs/tomato

zcat $DIR_BASE/assemblies/tomato/SL5.fa.gz > $DIR_BASE/vcfs/tomato/SL5.fa
samtools faidx $DIR_BASE/vcfs/tomato/SL5.fa
rtg format -o $DIR_BASE/vcfs/tomato/SL5.fa.sdf $DIR_BASE/vcfs/tomato/SL5.fa

# Transfer VCF files from Google Drive to /lizardfs/guarracino/pggb-paper/vcfs/tomato
# Fix header and apply PanSN
# Clean
rm $DIR_BASE/vcfs/tomato/*hifi.vcf.gz*

# Stratification
wget -c http://solomics.agis.org.cn/tomato/ftp/repeat/SL5.0.repeat.gff3.gz
zgrep -v "^#" SL5.0.repeat.gff3.gz | cut -f 1,4,5 | sort -k1,1V -k2,2n | bedtools merge -d 100 | sed 's/^/SL5#1#chr/g' | bedtools sort | bgzip -@ 48 -l 9 > SL5.hard.bed.gz # TE
bedtools subtract -a <(awk -v OFS='\t' '{print($1,"0",$2)}' $DIR_BASE/assemblies/tomato/SL5.fa.gz.fai) -b SL5.hard.bed.gz | bgzip -@ 48 -l 9 > SL5.easy.bed.gz

cd $DIR_BASE/evaluations_vcfeval
ls $DIR_GRAPHS/tomato*/*decomposed2.vcf.gz | grep chr6 | while read VCF; do
  NAME="$(dirname $VCF | rev | cut -f 1 -d '/' | rev)"
  CHR=$(echo $NAME | cut -f 2 -d '.' | cut -f 1 -d '_')
  echo $NAME

  sbatch -c 48 -p allnodes --job-name $NAME --wrap "hostname; bash $DIR_BASE/scripts/evaluation.speciesN.sh \
    $VCF \
    SL5#1#$CHR \
    $NAME \
    $DIR_BASE/evaluations_vcfeval \
    $DIR_BASE/vcfs/tomato/SL5.fa \
    $DIR_BASE/vcfs/tomato/SL5.fa.sdf \
    $DIR_BASE/vcfs/tomato \
    .hifi.pansn.vcf.gz \
    ".all":"" \
    ".easy":$DIR_BASE/vcfs/tomato/SL5.easy.bed.gz \
    ".hard":$DIR_BASE/vcfs/tomato/SL5.hard.bed.gz"
done

(echo chrom pos ac lv sample | tr ' ' '\t'; ls *.all/fp.vcf.gz | while read f; do SAMPLE=$(echo $f | cut -f 1 -d '.'); zcat $f | cut -f -8 | vcf2tsv | cut -f 1,2,8,15 | sed '1d' | awk -v OFS='\t' -v sample=$SAMPLE '{print($0,sample)}'; done) > all.fp.vcf.tsv


# A. thaliana
mkdir -p $DIR_BASE/vcfs/athaliana
cd $DIR_BASE/vcfs/athaliana

tabix -p bed $DIR_BASE/data/Ath.easy.region.bed.gz
tabix -p bed $DIR_BASE/data/Ath.hard.region.bed.gz

bcftools concat panCEN.dv.Chr*.vcf.gz | sed "s/Chr/Col-CC-v2#1#chr/g" | bgzip -@ 48 -l 9 > All.hifi.pansn.vcf.gz && tabix All.hifi.pansn.vcf.gz
rm panCEN.dv.Chr*.vcf.gz 

zgrep '^#CHROM' All.hifi.pansn.vcf.gz -m 1 | cut -f 10- | tr '\t' '\n' | while read SAMPLE; do
  echo $SAMPLE
  bcftools view --threads 48 -s $SAMPLE All.hifi.pansn.vcf.gz | bcftools norm -m -any -O u - | bcftools view --threads 48 -e 'GT="ref" | GT="0/." | GT="./0" | GT="./." | GT="0/1" | GT="1/0" |STRLEN(ALT)-STRLEN(REF)>=50 | STRLEN(ALT)-STRLEN(REF)<=-50|QUAL<30|DP<5|DP>400' -O z -l 9 -o $SAMPLE.hifi.pansn.vcf.gz
  tabix $SAMPLE.hifi.pansn.vcf.gz
done

# Fix names
SED_CMD=""
while IFS= read -r line; do
    search=$(echo "$line" | awk '{print $1}')
    replace=$(echo "$line" | awk '{print $2}')
    SED_CMD+="s/$search/$replace/g;"
done < $DIR_BASE/data/athaliana82.acc2name.tsv

zcat $DIR_BASE/assemblies/athaliana/GCA_028009825.2.fasta.gz | sed "$SED_CMD" | sed -e "s/CP116280.1/chr1/g" -e "s/CP116281.2/chr2/g" -e "s/CP116282.1/chr3/g" -e "s/CP116283.2/chr4/g" -e "s/CP116284.1/chr5/g" > $DIR_BASE/vcfs/athaliana/Col-CC-v2.fa
samtools faidx $DIR_BASE/vcfs/athaliana/Col-CC-v2.fa
rtg format -o $DIR_BASE/vcfs/athaliana/Col-CC-v2.fa.sdf $DIR_BASE/vcfs/athaliana/Col-CC-v2.fa

ls $DIR_GRAPHS/athaliana*/*decomposed.vcf.gz | while read VCF; do
  echo $VCF

  PREFIX=$(echo $VCF | sed 's/.vcf.gz//g')
  zcat $VCF | sed "$SED_CMD" | sed -e "s/CP116280.1/chr1/g" -e "s/CP116281.2/chr2/g" -e "s/CP116282.1/chr3/g" -e "s/CP116283.2/chr4/g" -e "s/CP116284.1/chr5/g" | bcftools sort -m 40G -T /scratch/bcftools-sort.XXXXXX | bgzip -@ 48 -l 9 > $PREFIX.renamed.vcf.gz
  tabix $PREFIX.renamed.vcf.gz
done

cd $DIR_BASE/evaluations_vcfeval
ls $DIR_GRAPHS/athaliana*/*decomposed.renamed.vcf.gz | while read VCF; do
  NAME="$(dirname $VCF | rev | cut -f 1 -d '/' | rev)"
  CHR=$(echo $NAME | cut -f 2 -d '.' | cut -f 1 -d '_')
  echo $NAME

  sbatch -c 48 -p headnode --job-name $NAME --wrap "hostname; bash $DIR_BASE/scripts/evaluation.speciesN.sh \
    $VCF \
    Col-CC-v2#1#$CHR \
    $NAME \
    $DIR_BASE/evaluations_vcfeval \
    $DIR_BASE/vcfs/athaliana/Col-CC-v2.fa \
    $DIR_BASE/vcfs/athaliana/Col-CC-v2.fa.sdf \
    $DIR_BASE/vcfs/athaliana \
    .hifi.pansn.vcf.gz \
    ".all":"" \
    ".easy":$DIR_BASE/data/Ath.easy.region.bed.gz \
    ".hard":$DIR_BASE/data/Ath.hard.region.bed.gz"
done



cd $DIR_BASE/evaluations_vcfeval
echo pangenome chromosome parameters sample stratification tp.baseline tp.call fp fn precision recall f1.score | tr ' ' '\t' > evaluation.tsv
ls | grep evaluation -v | grep slurm -v | cut -f 1 -d '.' | sort | uniq | while read PANGENOME; do
  for STRATIFICATION in all easy hard; do
    grep None $PANGENOME*/vcfeval/*.$STRATIFICATION/summary.txt | tr -s ' ' | awk -v OFS='\t' '
        {
            split($1, arr1, "_");
            split(arr1[1], arr2, ".")
            pangenome = arr2[1]
            chromosome = arr2[2]
            parameters = arr1[2];

            split($1, arr3, "/");
            split(arr3[3], arr4, ".");
            sample = arr4[1];
            stratification = arr4[2];

            printf "%s%s%s%s%s%s%s%s%s", pangenome, OFS, chromosome, OFS, parameters, OFS, sample, OFS, stratification;
            for (i = 3; i <= 6; i++) {
                printf "%s%d", OFS, $i;  # Print 3rd to 7th fields as integers
            }
            for (i = 7; i <= NF; i++) {
                printf "%s%.4f", OFS, $i;  # Print remaining fields with four decimal places
            }
            print "";  # New line at the end of each record
        }'
  done
done | sort -V >> evaluation.tsv

# Group chromosomes together (on human, it just averages the samples)
(echo "pangenome" "parameters" "stratification" "tp.baseline" "tp.call" "fp" "fn" "precision" "recall" "f1.score" | tr ' ' '\t'; awk '
    BEGIN { FS=OFS="\t" }
    NR > 1 {
        key = $1 FS $3 FS $5;  # Create a key for grouping, using FS as separator
        count[key]++;

        # Accumulate values for each numeric column
        for (i = 6; i <= NF; i++) {
            sum[key, i] += $i;
        }
    }
    END {
        # Calculate and print averages
        for (key in count) {
            split(key, arr, FS);  # Split the key into its components
            printf "%s%s%s%s%s", arr[1], OFS, arr[2], OFS, arr[3];  # Print the components of the key
            for (i = 6; i <= NF; i++) {
                printf "%s%.4f", OFS, sum[key, i] / count[key];
            }
            print "";
        }
    }
' evaluation.tsv | sort -V) > evaluation.mean.tsv
```

Compression:

```shell
cd $DIR_GRAPHS

(echo "dataset graph.len pangenome.len compression.ratio" | tr ' ' '\t'; ls $DIR_GRAPHS/*/*.final.og | while read GRAPH; do
  DIR_PARENT="$(dirname $GRAPH)"
  NAME=$(echo $GRAPH | rev | cut -f 2 -d '/' | rev)
  PREFIX=$DIR_PARENT/$NAME

  GRAPH_LEN=$($ODGI stats -i $GRAPH -S | tail -n 1 | cut -f 1)
  PANGENOME_LEN=$(cat $(grep Command $DIR_PARENT/*.log -m 1 | cut -f 4 -d ' ').fai | awk '{sum+=$2}END{print(sum)}')
  echo $NAME $GRAPH_LEN $PANGENOME_LEN | awk -v OFS='\t' '{print($0,$3/$2)}'
done) > compression.stats.tsv

# Group chromosomes together
grep 'athaliana\|tomato\|soy' compression.stats.tsv | awk -v OFS='\t' '
    {
        split($1, arr1, ".");
        split($1, arr2, "_");
        key = arr1[1] "_" arr2[2];
        a[key] += $2;
        b[key] += $3;
    }
    END {
        for (key in a) {
            print(key, a[key], b[key], b[key]/a[key]);
        } 
    }
' | sort -V | column -t
```

Openness:

```shell
cd $DIR_GRAPHS

convert -size 100x50 xc:white spacer.png

ls $DIR_GRAPHS/*/*gfa | grep ecoli500_p90.s5000.n500.k17.G700-900-1100.Pasm5.O0001_1.xauto | while read GRAPH; do
  DIR_PARENT="$(dirname $GRAPH)"
  NAME=$(echo $GRAPH | rev | cut -f 2 -d '/' | rev)
  PREFIX=$DIR_PARENT/$NAME
  #NUM=$(echo $NAME | cut -f 1 -d '.' | grep -oP '\d+$')
  echo $PREFIX
  #sbatch -c 48 -p tux --job-name panacus-$NAME --wrap "hostname; $PANACUS histgrowth $GRAPH -c bp -q 0,1,0.5,0.1 --groupby-sample -t 48 > $PREFIX.histgrowth.tsv; $PANACUS_VISUALIZE --estimate_growth_params $PREFIX.histgrowth.tsv -s 15 10 > $PREFIX.histgrowth.pdf"
  #$PANACUS histgrowth $GRAPH -c bp -q 0,1,0.5,0.1 --groupby-sample -t 48 > $PREFIX.histgrowth.tsv
  
  $PANACUS histgrowth $GRAPH -c bp -q 0 --groupby-sample -t 48 > $PREFIX.histgrowth.tsv #e ecoli500
  $PANACUS_VISUALIZE --estimate_growth_params $PREFIX.histgrowth.tsv -s 13 9 --split_subfigures # ecoli500 (hack `panacus-visualize.py` to hide x-labels)
  $PANACUS_VISUALIZE --estimate_growth_params $PREFIX.histgrowth.tsv -s 13 9 -f svg --split_subfigures # ecoli500 (hack `panacus-visualize.py` to hide x-labels)
  mv out_0_0.svg $PREFIX.histgrowth.svg
  mv out_0_1.svg $PREFIX.coverage.svg

  # guix install imagemagick
  mv out_0_0.pdf $PREFIX.histgrowth.pdf
  mv out_0_1.pdf $PREFIX.coverage.pdf
  convert -density 300 $PREFIX.histgrowth.pdf $PREFIX.histgrowth.png
  convert -density 300 $PREFIX.coverage.pdf $PREFIX.coverage.png
  convert -append $PREFIX.histgrowth.png spacer.png $PREFIX.coverage.png $PREFIX.histgrowth+coverage.png
done


#for SPECIES in athaliana82 tomato23 soy37; do
for SPECIES in soy37; do
  echo $SPECIES

  sed '1d' $PATH_PANGENOMES_TSV | sort -k 4n | grep $SPECIES | while read f p s n k G POA O REF; do
    seq 1 1 | while read c; do
      #echo $f $p $s $n $k $G $POA $O $REF $c;

      SUFFIX=p$p.s$s.n$n.k$k.G$(echo $G | tr ',' '-').P$POA.O$(echo $O | sed 's/\.//g')_$c
      echo $SUFFIX
    done
  done | sort | uniq | while read SUFFIX; do
    echo $SUFFIX
    PREFIX=$DIR_GRAPHS/$SPECIES.$SUFFIX
    GRAPH=$PREFIX.gfa
    #$PANACUS histgrowth $GRAPH -c bp -q 0,1,0.5,0.1 --groupby-sample -t 48 > $PREFIX.histgrowth.tsv
    #$PANACUS_VISUALIZE --estimate_growth_params $PREFIX.histgrowth.tsv -s 14 9 --split_subfigures # athaliana82
    #$PANACUS_VISUALIZE --estimate_growth_params $PREFIX.histgrowth.tsv -s 12 9 --split_subfigures # tomato23
    $PANACUS_VISUALIZE --estimate_growth_params $PREFIX.histgrowth.tsv -s 13 9 --split_subfigures # soy37
    
    # guix install imagemagick
    mv out_0_0.pdf $PREFIX.histgrowth.pdf
    mv out_0_1.pdf $PREFIX.coverage.pdf
    convert -density 300 $PREFIX.histgrowth.pdf $PREFIX.histgrowth.png
    convert -density 300 $PREFIX.coverage.pdf $PREFIX.coverage.png
    convert -append $PREFIX.histgrowth.png spacer.png $PREFIX.coverage.png $PREFIX.histgrowth+coverage.png
  done
done
```

Non-reference-sequences:

```shell
cd $DIR_GRAPHS
f=athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1
$ODGI paths -i $DIR_GRAPHS/$f.og -L | grep GCA_028009825.2 | cut -f 1 > $DIR_GRAPHS/$f.ref-contigs.txt
f=athaliana82.p95.s5000.n82.k23.G700-900-1100.Pasm5.O0001_1
$ODGI paths -i $DIR_GRAPHS/$f.og -L | grep GCA_028009825.2 | cut -f 1 > $DIR_GRAPHS/$f.ref-contigs.txt
f=tomato23.p95.s5000.n23.k17.G700-900-1100.Pasm5.O0001_1
$ODGI paths -i $DIR_GRAPHS/$f.og -L | grep SL5 | cut -f 1 > $DIR_GRAPHS/$f.ref-contigs.txt

mkdir -p $DIR_BASE/non-reference-sequence
cd $DIR_BASE/non-reference-sequence

#for f in athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1 athaliana82.p95.s5000.n82.k23.G700-900-1100.Pasm5.O0001_1 tomato23.p95.s5000.n23.k17.G700-900-1100.Pasm5.O0001_1; do
for f in athaliana82.p95.s5000.n82.k23.G700-900-1100.Pasm5.O0001_1; do
  SPECIES=$(echo $f | cut -f 1 -d '.')

  mkdir -p $DIR_BASE/non-reference-sequence/$SPECIES
  sbatch -c 48 -p workers --job-name $(echo $f | cut -f 1 -d '.')-non-ref-ranges --wrap "hostname; cd /scratch; $ODGI paths -i $DIR_GRAPHS/$f.og --non-reference-ranges $DIR_GRAPHS/$f.ref-contigs.txt -t 48 | bedtools sort > $f.non-reference-ranges.bed; bgzip -@ 48 -l 9 $f.non-reference-ranges.bed; mv $f.non-reference-ranges.bed.gz $DIR_BASE/non-reference-sequence/$SPECIES"
done

# Download annotaton

# PanSN for the annotation
cd $DIR_BASE/non-reference-sequence/tomato23
ls $DIR_BASE/non-reference-sequence/tomato23/annotation/*gff3.gz | while read f; do
  NAME=$(basename $f .gff3.gz | cut -f 1 -d '.')
  echo $f $NAME
  zcat $f | sed -e 's/chr0\([0-9]\)/chr\1/' -e 's/^\([0-9]\|10\|11\|12\)$/chr\1/' | sed "s/chr/${NAME}#1#chr/g" | bgzip -@ 48 -l 9 > $DIR_BASE/non-reference-sequence/tomato23/annotation/$NAME.pansn.gff3.gz
done

# >50bps nodes
zcat tomato23.p95.s5000.n23.k17.G700-900-1100.Pasm5.O0001_1.non-reference-ranges.bed.gz | awk '$3-$2>50' | bedtools sort | bgzip -@ 48 -l 9 > tomato23.p95.s5000.n23.k17.G700-900-1100.Pasm5.O0001_1.non-reference-ranges.50bp.bed.gz

NAME=MM
bedtools intersect -a tomato23.p95.s5000.n23.k17.G700-900-1100.Pasm5.O0001_1.non-reference-ranges.50bp.bed.gz -b $DIR_BASE/non-reference-sequence/tomato23/annotation/$NAME.pansn.gff3.gz -wa -wb | cut -f4-20 > $NAME.tmp.gff3
cat $NAME.tmp.gff3 | perl $DIR_BASE/scripts/gff2out.pl > $NAME.tmp.out

conda activate /lizardfs/guarracino/condatools/edta/2.1.0
perl /lizardfs/guarracino/git/EDTA/util/buildSummary.pl $NAME.tmp.out > $NAME.tmp.tbl
conda deactivate

rm $NAME.tmp.gff3 $NAME.tmp.out
```

Visualization by merging contigs by haplotype:

```shell
cd $DIR_BASE

ls $DIR_GRAPHS/*/*.final.og | while read GRAPH; do
  DIR_PARENT="$(dirname $GRAPH)"
  NAME=$(echo $GRAPH | rev | cut -f 2 -d '/' | rev)
  PREFIX=$DIR_PARENT/$NAME
  echo $NAME

  if [[ ! -s $PREFIX.prefixes.txt ]]; then
    $ODGI paths -i $GRAPH -L | cut -f 1,2 -d '#' | sort | uniq > $PREFIX.prefixes.txt
  fi
  
  sbatch -c 8 -p workers -J $NAME-N  --wrap "hostname; $ODGI viz -i $GRAPH -o $PREFIX.merged_by_haplotype.N.png  -x 1000 -y 500 -a 10 -N  -I Consensus_ -M $PREFIX.prefixes.txt"
  sbatch -c 8 -p workers -J $NAME-z  --wrap "hostname; $ODGI viz -i $GRAPH -o $PREFIX.merged_by_haplotype.z.png  -x 1000 -y 500 -a 10 -z  -I Consensus_ -M $PREFIX.prefixes.txt"
  sbatch -c 8 -p workers -J $NAME-du --wrap "hostname; $ODGI viz -i $GRAPH -o $PREFIX.merged_by_haplotype.du.png -x 1000 -y 500 -a 10 -du -I Consensus_ -M $PREFIX.prefixes.txt"
done
```

Check A. thaliana PGGB-NUCMER evaluation:

```shell
cd $DIR_EVALUATIONS
(echo "CHROM\tPOS\tAC\tAF\tLV\tSAMPLE\tCHROMOSOME"; ls athaliana82.chr*_p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1/vcfeval/haplo.waved/*/fp.vcf.gz | while read VCF; do
  CHR=$(echo $VCF | cut -f 2 -d '.' | cut -f 1 -d '_')
  SAMPLE=$(echo $VCF | rev | cut -f 2 -d '/' | rev)
 
  zcat $VCF | cut -f -8 | vcf2tsv | cut -f 1,2,8,9,15 | sed '1d' | awk -v OFS='\t' -v chr=$CHR -v sample=$SAMPLE '{print($0,sample,chr)}'
done) | pigz -9 > athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1.fp.tsv.gz

(echo "CHROM\tPOS\tSAMPLE\tCHROMOSOME"; ls athaliana82.chr*_p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1/vcfeval/haplo.waved/*/fn.vcf.gz | while read VCF; do
  CHR=$(echo $VCF | cut -f 2 -d '.' | cut -f 1 -d '_')
  SAMPLE=$(echo $VCF | rev | cut -f 2 -d '/' | rev)
  
  zcat $VCF | cut -f -8 | vcf2tsv | cut -f 1,2 | sed '1d' | awk -v OFS='\t' -v chr=$CHR -v sample=$SAMPLE '{print($0,sample,chr)}'
done) | pigz -9 > athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1.fn.tsv.gz

echo "CHROM\tPOS\tSAMPLE\tCHROMOSOME\tTYPE" > athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1.fp+fn.tsv
zcat athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1.fp.tsv.gz | sed '1d' | cut -f 1,2,6,7 | awk -v OFS='\t' '{print($0,"FP")}' >> athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1.fp+fn.tsv
zcat athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1.fn.tsv.gz | sed '1d' | cut -f 1,2,3,4 | awk -v OFS='\t' '{print($0,"FN")}' >> athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1.fp+fn.tsv
pigz -9 athaliana82.p95.s5000.n82.k47.G700-900-1100.Pasm5.O0001_1.fp+fn.tsv


(echo chrom pos ac sample | tr ' ' '\t'; ls *.all/fn.vcf.gz | while read f; do SAMPLE=$(echo $f | cut -f 1 -d '.'); zcat $f | cut -f -8 | vcf2tsv | cut -f 1,2,8 | sed '1d' | awk -v OFS='\t' -v sample=$SAMPLE '{print($0,sample)}'; done) > all.fn.vcf.tsv
```